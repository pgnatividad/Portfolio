{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB,BernoulliNB\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "thunder_3y = pd.read_csv('../datasets/thunder/tc_3yr_4com.csv')\n",
    "thunder_2y = pd.read_csv('../datasets/thunder/tc_2yr_4com.csv')\n",
    "thunder_1y = pd.read_csv('../datasets/thunder/tc_1yr_4com.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulls_3y = pd.read_csv('../datasets/bulls/bc_3yrs_4com.csv')\n",
    "bulls_2y = pd.read_csv('../datasets/bulls/bc_2yrs_4com.csv')\n",
    "bulls_1y = pd.read_csv('../datasets/bulls/bc_1yrs_4com.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "thunder_df = pd.concat([thunder_1y,thunder_2y,thunder_3y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12707, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thunder_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulls_df = pd.concat([bulls_3y,bulls_2y,bulls_1y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11891, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bulls_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "thunder_df['is_thunder'] = 1\n",
    "bulls_df['is_thunder'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code taken from heather robbins lesson\n",
    "\n",
    "thunder_df['body+title']=thunder_df['body+title'].replace('http\\S+', '', regex=True).replace('www\\S+', '', regex=True).replace('\\n\\n\\S+', '', regex=True).replace('\\n\\S+','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bulls_df['body+title']=bulls_df['body+title'].replace('http\\S+', '', regex=True).replace('www\\S+', '', regex=True).replace('\\n\\n\\S+', '', regex=True).replace('\\n\\S+','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12707, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thunder_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11891, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bulls_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([thunder_df,bulls_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_df['body+title']\n",
    "y = combined_df['is_thunder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(['deleted','removed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipelines with logistic regression predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pipe_log = Pipeline(\n",
    "    [\n",
    "        ('cvec',CountVectorizer()),\n",
    "        ('logreg',LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "tv_pipe_log = Pipeline(\n",
    "    [\n",
    "        ('tvec',TfidfVectorizer()),\n",
    "        ('logreg',LogisticRegression())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pipe_log_params ={\n",
    "    'cvec__max_features':[5000,10000,15000],\n",
    "    'cvec__stop_words':['english',stop_words],\n",
    "    'cvec__ngram_range':[(1,1),(1,2)],\n",
    "    'logreg__penalty': ['l1','l2'],\n",
    "    'logreg__n_jobs':[-1],\n",
    "    'logreg__C':[.01,.5,1]\n",
    "}\n",
    "\n",
    "tv_pipe_log_params ={\n",
    "    'tvec__max_features':[5000,10000,15000],\n",
    "    'tvec__stop_words':['english',stop_words],\n",
    "    'tvec__ngram_range':[(1,1),(1,2)],\n",
    "    'logreg__penalty': ['l1','l2'],\n",
    "    'logreg__n_jobs':[-1],\n",
    "    'logreg__C':[.01,.5,1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14758,), (14758,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.73002696037292\n",
      "0.910828025477707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 15000,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': frozenset({'a',\n",
       "            'about',\n",
       "            'above',\n",
       "            'across',\n",
       "            'after',\n",
       "            'afterwards',\n",
       "            'again',\n",
       "            'against',\n",
       "            'all',\n",
       "            'almost',\n",
       "            'alone',\n",
       "            'along',\n",
       "            'already',\n",
       "            'also',\n",
       "            'although',\n",
       "            'always',\n",
       "            'am',\n",
       "            'among',\n",
       "            'amongst',\n",
       "            'amoungst',\n",
       "            'amount',\n",
       "            'an',\n",
       "            'and',\n",
       "            'another',\n",
       "            'any',\n",
       "            'anyhow',\n",
       "            'anyone',\n",
       "            'anything',\n",
       "            'anyway',\n",
       "            'anywhere',\n",
       "            'are',\n",
       "            'around',\n",
       "            'as',\n",
       "            'at',\n",
       "            'back',\n",
       "            'be',\n",
       "            'became',\n",
       "            'because',\n",
       "            'become',\n",
       "            'becomes',\n",
       "            'becoming',\n",
       "            'been',\n",
       "            'before',\n",
       "            'beforehand',\n",
       "            'behind',\n",
       "            'being',\n",
       "            'below',\n",
       "            'beside',\n",
       "            'besides',\n",
       "            'between',\n",
       "            'beyond',\n",
       "            'bill',\n",
       "            'both',\n",
       "            'bottom',\n",
       "            'but',\n",
       "            'by',\n",
       "            'call',\n",
       "            'can',\n",
       "            'cannot',\n",
       "            'cant',\n",
       "            'co',\n",
       "            'con',\n",
       "            'could',\n",
       "            'couldnt',\n",
       "            'cry',\n",
       "            'de',\n",
       "            'deleted',\n",
       "            'describe',\n",
       "            'detail',\n",
       "            'do',\n",
       "            'done',\n",
       "            'down',\n",
       "            'due',\n",
       "            'during',\n",
       "            'each',\n",
       "            'eg',\n",
       "            'eight',\n",
       "            'either',\n",
       "            'eleven',\n",
       "            'else',\n",
       "            'elsewhere',\n",
       "            'empty',\n",
       "            'enough',\n",
       "            'etc',\n",
       "            'even',\n",
       "            'ever',\n",
       "            'every',\n",
       "            'everyone',\n",
       "            'everything',\n",
       "            'everywhere',\n",
       "            'except',\n",
       "            'few',\n",
       "            'fifteen',\n",
       "            'fifty',\n",
       "            'fill',\n",
       "            'find',\n",
       "            'fire',\n",
       "            'first',\n",
       "            'five',\n",
       "            'for',\n",
       "            'former',\n",
       "            'formerly',\n",
       "            'forty',\n",
       "            'found',\n",
       "            'four',\n",
       "            'from',\n",
       "            'front',\n",
       "            'full',\n",
       "            'further',\n",
       "            'get',\n",
       "            'give',\n",
       "            'go',\n",
       "            'had',\n",
       "            'has',\n",
       "            'hasnt',\n",
       "            'have',\n",
       "            'he',\n",
       "            'hence',\n",
       "            'her',\n",
       "            'here',\n",
       "            'hereafter',\n",
       "            'hereby',\n",
       "            'herein',\n",
       "            'hereupon',\n",
       "            'hers',\n",
       "            'herself',\n",
       "            'him',\n",
       "            'himself',\n",
       "            'his',\n",
       "            'how',\n",
       "            'however',\n",
       "            'hundred',\n",
       "            'i',\n",
       "            'ie',\n",
       "            'if',\n",
       "            'in',\n",
       "            'inc',\n",
       "            'indeed',\n",
       "            'interest',\n",
       "            'into',\n",
       "            'is',\n",
       "            'it',\n",
       "            'its',\n",
       "            'itself',\n",
       "            'keep',\n",
       "            'last',\n",
       "            'latter',\n",
       "            'latterly',\n",
       "            'least',\n",
       "            'less',\n",
       "            'ltd',\n",
       "            'made',\n",
       "            'many',\n",
       "            'may',\n",
       "            'me',\n",
       "            'meanwhile',\n",
       "            'might',\n",
       "            'mill',\n",
       "            'mine',\n",
       "            'more',\n",
       "            'moreover',\n",
       "            'most',\n",
       "            'mostly',\n",
       "            'move',\n",
       "            'much',\n",
       "            'must',\n",
       "            'my',\n",
       "            'myself',\n",
       "            'name',\n",
       "            'namely',\n",
       "            'neither',\n",
       "            'never',\n",
       "            'nevertheless',\n",
       "            'next',\n",
       "            'nine',\n",
       "            'no',\n",
       "            'nobody',\n",
       "            'none',\n",
       "            'noone',\n",
       "            'nor',\n",
       "            'not',\n",
       "            'nothing',\n",
       "            'now',\n",
       "            'nowhere',\n",
       "            'of',\n",
       "            'off',\n",
       "            'often',\n",
       "            'on',\n",
       "            'once',\n",
       "            'one',\n",
       "            'only',\n",
       "            'onto',\n",
       "            'or',\n",
       "            'other',\n",
       "            'others',\n",
       "            'otherwise',\n",
       "            'our',\n",
       "            'ours',\n",
       "            'ourselves',\n",
       "            'out',\n",
       "            'over',\n",
       "            'own',\n",
       "            'part',\n",
       "            'per',\n",
       "            'perhaps',\n",
       "            'please',\n",
       "            'put',\n",
       "            'rather',\n",
       "            're',\n",
       "            'removed',\n",
       "            'same',\n",
       "            'see',\n",
       "            'seem',\n",
       "            'seemed',\n",
       "            'seeming',\n",
       "            'seems',\n",
       "            'serious',\n",
       "            'several',\n",
       "            'she',\n",
       "            'should',\n",
       "            'show',\n",
       "            'side',\n",
       "            'since',\n",
       "            'sincere',\n",
       "            'six',\n",
       "            'sixty',\n",
       "            'so',\n",
       "            'some',\n",
       "            'somehow',\n",
       "            'someone',\n",
       "            'something',\n",
       "            'sometime',\n",
       "            'sometimes',\n",
       "            'somewhere',\n",
       "            'still',\n",
       "            'such',\n",
       "            'system',\n",
       "            'take',\n",
       "            'ten',\n",
       "            'than',\n",
       "            'that',\n",
       "            'the',\n",
       "            'their',\n",
       "            'them',\n",
       "            'themselves',\n",
       "            'then',\n",
       "            'thence',\n",
       "            'there',\n",
       "            'thereafter',\n",
       "            'thereby',\n",
       "            'therefore',\n",
       "            'therein',\n",
       "            'thereupon',\n",
       "            'these',\n",
       "            'they',\n",
       "            'thick',\n",
       "            'thin',\n",
       "            'third',\n",
       "            'this',\n",
       "            'those',\n",
       "            'though',\n",
       "            'three',\n",
       "            'through',\n",
       "            'throughout',\n",
       "            'thru',\n",
       "            'thus',\n",
       "            'to',\n",
       "            'together',\n",
       "            'too',\n",
       "            'top',\n",
       "            'toward',\n",
       "            'towards',\n",
       "            'twelve',\n",
       "            'twenty',\n",
       "            'two',\n",
       "            'un',\n",
       "            'under',\n",
       "            'until',\n",
       "            'up',\n",
       "            'upon',\n",
       "            'us',\n",
       "            'very',\n",
       "            'via',\n",
       "            'was',\n",
       "            'we',\n",
       "            'well',\n",
       "            'were',\n",
       "            'what',\n",
       "            'whatever',\n",
       "            'when',\n",
       "            'whence',\n",
       "            'whenever',\n",
       "            'where',\n",
       "            'whereafter',\n",
       "            'whereas',\n",
       "            'whereby',\n",
       "            'wherein',\n",
       "            'whereupon',\n",
       "            'wherever',\n",
       "            'whether',\n",
       "            'which',\n",
       "            'while',\n",
       "            'whither',\n",
       "            'who',\n",
       "            'whoever',\n",
       "            'whole',\n",
       "            'whom',\n",
       "            'whose',\n",
       "            'why',\n",
       "            'will',\n",
       "            'with',\n",
       "            'within',\n",
       "            'without',\n",
       "            'would',\n",
       "            'yet',\n",
       "            'you',\n",
       "            'your',\n",
       "            'yours',\n",
       "            'yourself',\n",
       "            'yourselves'}),\n",
       " 'logreg__C': 0.5,\n",
       " 'logreg__n_jobs': -1,\n",
       " 'logreg__penalty': 'l2'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time.time()\n",
    "gs = GridSearchCV(cv_pipe_log, param_grid=cv_pipe_log_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(time.time()-t0)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_\n",
    "#0.9108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9136061796991463\n",
      "209.40227627754211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 1,\n",
       " 'logreg__n_jobs': -1,\n",
       " 'logreg__penalty': 'l2',\n",
       " 'tvec__max_features': 15000,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time.time()\n",
    "gs = GridSearchCV(tv_pipe_log, param_grid=tv_pipe_log_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(time.time()-t0)\n",
    "gs.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines with Naive Bayes models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines in MNB model\n",
    "cv_pipe_mnb = Pipeline(\n",
    "    [\n",
    "        ('cvec',CountVectorizer()),\n",
    "        ('mnb',MultinomialNB())\n",
    "    ]\n",
    ")\n",
    "\n",
    "tv_pipe_mnb = Pipeline(\n",
    "    [\n",
    "        ('tvec',TfidfVectorizer()),\n",
    "        ('mnb',MultinomialNB())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pipe_mnb_params ={\n",
    "    'cvec__max_features':[5000,10000,15000],\n",
    "    'cvec__stop_words':['english',stop_words],\n",
    "    'cvec__ngram_range':[(1,1),(1,2)],\n",
    "    'mnb__alpha':[0.01,0.5,1],\n",
    "}\n",
    "\n",
    "tv_pipe_mnb_params ={\n",
    "    'tvec__max_features':[5000,10000,15000],\n",
    "    'tvec__stop_words':['english',stop_words],\n",
    "    'tvec__ngram_range':[(1,1),(1,2)],\n",
    "    'mnb__alpha':[0.01,0.5,1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9100826670280526\n",
      "104.763356924057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 15000,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'mnb__alpha': 1}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time.time()\n",
    "gs = GridSearchCV(cv_pipe_mnb,param_grid=cv_pipe_mnb_params,cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(time.time()-t0)\n",
    "gs.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9054072367529475\n",
      "104.89422297477722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mnb__alpha': 0.5,\n",
       " 'tvec__max_features': 15000,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time.time()\n",
    "gs = GridSearchCV(tv_pipe_mnb,param_grid=tv_pipe_mnb_params,cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(time.time()-t0)\n",
    "gs.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pipe_bnb = Pipeline(\n",
    "    [\n",
    "        ('cvec',CountVectorizer()),\n",
    "        ('bnb',BernoulliNB())\n",
    "    ]\n",
    ")\n",
    "\n",
    "tv_pipe_bnb = Pipeline(\n",
    "    [\n",
    "        ('tvec',TfidfVectorizer()),\n",
    "        ('bnb',BernoulliNB())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pipe_bnb_params ={\n",
    "    'cvec__max_features':[5000,10000,15000],\n",
    "    'cvec__stop_words':['english',stop_words],\n",
    "    'cvec__ngram_range':[(1,1),(1,2)],\n",
    "    'bnb__alpha':[0.01,0.5,1],\n",
    "}\n",
    "\n",
    "tv_pipe_bnb_params ={\n",
    "    'tvec__max_features':[5000,10000,15000],\n",
    "    'tvec__stop_words':['english',stop_words],\n",
    "    'tvec__ngram_range':[(1,1),(1,2)],\n",
    "    'bnb__alpha':[0.01,0.5,1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8930749424041198\n",
      "104.69995093345642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bnb__alpha': 0.01,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time.time()\n",
    "gs = GridSearchCV(cv_pipe_bnb,param_grid=cv_pipe_bnb_params,cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(time.time()-t0)\n",
    "gs.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8930749424041198\n",
      "104.54622983932495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bnb__alpha': 0.01,\n",
       " 'tvec__max_features': 5000,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time.time()\n",
    "gs = GridSearchCV(tv_pipe_bnb,param_grid=tv_pipe_bnb_params,cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(time.time()-t0)\n",
    "gs.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24598, 7)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
